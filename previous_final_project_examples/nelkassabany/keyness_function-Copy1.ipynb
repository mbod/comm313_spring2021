{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_keyness(fdist1, fdist2, fthreshold=5, keyness_threshold=6.6, top=100, print_table=True):\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    c1size = sum(fdist1.values())\n",
    "    c2size = sum(fdist2.values())\n",
    "\n",
    "    \n",
    "    kdata = []\n",
    "    \n",
    "    for item, freq in fdist1.items():\n",
    "        if freq<fthreshold:\n",
    "            continue\n",
    "            \n",
    "        ref_freq = fdist2.get(item,0)\n",
    "        \n",
    "        if ref_freq<fthreshold:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        keyness = log_likelihood(freq, c1size, ref_freq, c2size)\n",
    "        \n",
    "        row = {'item': item, 'freq': freq, 'ref_freq': ref_freq, 'keyness': keyness}\n",
    "        \n",
    "        if keyness>keyness_threshold:\n",
    "        \n",
    "            kdata.append(row)\n",
    "        \n",
    "    \n",
    "    kdf = pd.DataFrame(kdata)[['item', 'freq', 'ref_freq', 'keyness']]\n",
    "    \n",
    "    kdf=kdf.sort_values('keyness', ascending=False)\n",
    "    \n",
    "    if not print_table:\n",
    "        return kdf[:top]\n",
    "    \n",
    "    template = \"{: <25}{: <10}{: <10}{:0.3f}\"\n",
    "    \n",
    "    header = \"{: <25}{: <10}{: <10}{}\".format('WORD', 'Corpus Freq.', 'RC Freq.', 'Keyness')\n",
    "    \n",
    "    print(\"{}\\n{}\".format(header, \"=\"*len(header)))\n",
    "    \n",
    "    for item, freq, ref_freq, keyness in kdf[:top].values:\n",
    "        print(template.format(item, freq, ref_freq, keyness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(item_A_freq, corpus_A_size, item_B_freq, corpus_B_size):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    E1 = corpus_A_size*(item_A_freq+item_B_freq) / (corpus_A_size+corpus_B_size)\n",
    "    E2 = corpus_B_size*(item_A_freq+item_B_freq) / (corpus_A_size+corpus_B_size)\n",
    "\n",
    "    G2 = 2*((item_A_freq*math.log(item_A_freq/E1)) + (item_B_freq*math.log(item_B_freq/E2)))\n",
    "    \n",
    "    sign = 1 if (item_A_freq / corpus_A_size) >= (item_B_freq / corpus_B_size) else -1\n",
    "    \n",
    "    return sign*G2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, lowercase=False, strip_chars=''):\n",
    "    '''create a list of tokens from a string by splitting on whitespace and applying optional normalization \n",
    "    \n",
    "    Args:\n",
    "        text        -- a string object containing the text to be tokenized\n",
    "        lowercase   -- should text string be normalized as lowercase (default: False)\n",
    "        strip_chars -- a string indicating characters to strip out of text, e.g. punctuation (default: empty string) \n",
    "        \n",
    "    Return:\n",
    "        A list of tokens\n",
    "    '''\n",
    "    \n",
    "    # create a replacement dictionary from the\n",
    "    # string of characters in the **strip_chars**\n",
    "    rdict = str.maketrans('','',strip_chars)\n",
    "    \n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "    \n",
    "    tokens = text.translate(rdict).split()\n",
    "    \n",
    "    return tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
