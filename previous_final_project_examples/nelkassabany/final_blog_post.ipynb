{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run 'lyrics_analysis.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does it take to win SOTY? Lyrical analysis of Grammy Song of the Year winners and nominees\n",
    "\n",
    "### Nour Elkassabany\n",
    "### COMM313 SPRING2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTRODUCTION\n",
    "\n",
    "Despite perennial debates of the Grammys’ relevance and objections of #GrammysTooWhite, the Recording Academy’s awards remain one of the most legible ways of signaling achievement or recognition in the music industry.\n",
    "\n",
    "Because so few of the (as of 2017) 84 awards handed out are not part of the televised program and so many inherently subjective factors contribute to song selection, like interpretation of “excellence” and “prominence” and the particularities of voting members’ tastes, the Grammy Awards are something of a black box. The aim of this project, then, is to see what insights we might find by taking a closer look into one of the major awards, Song of the Year (SOTY). \n",
    "\n",
    "The Song of the Year award “recognizes the songwriter(s) who wrote and composed the song.” It is distinct from Record of the Year, which “recognizes the artist’s performance as well as the overall contributions of the producer(s), recording engineer(s), and/or mixer(s), if other than the performing artist” (grammys.com). Along with the awards for Album of the Year and Best New Artist, these make up the “Big Four” at the Grammys each year. \n",
    "\n",
    "Using the body of songs that have been nominated for the Song of the Year Award since the first award year in 1959 to present day, I will explore if lyrical patterns in the winners imply a certain “formula” or strategy of songwriting to create a winning song. Thus, the primary dimension of analysis is award status (winner or nominee).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COLLECTING THE CORPUS\n",
    "Information about the recipients is contained in a single table on the Wikipedia page for the Song of the Year award (https://en.wikipedia.org/wiki/Grammy_Award_for_Song_of_the_Year). I utilized web scraping to obtain the award year, names of the winner(s) of the award, titles of songs, and performing artists. A similar process was used for the nominees, for which there was a column within in the recipients table containing nominees, title of song, and performing artist. This information was stored in two list of dictionaries structures (one for winners, one for nominees), where each dictionary in the list contains the relevant details for each song.\n",
    "\n",
    "The Genius.com API was then used to retrieve the lyrics for the songs. I addressed cases of Genius returning no results or incorrect results manually. Because the corpora were small, the length of song lyrics was typically short, and song lyrics usually contain repetition, mistakes were easily detected visually. These cases were often borne out of discrepancies in how certain details were displayed on Wikipedia versus Genius, particularly for songs with featured artists, songs written for films or musicals, songs that were covers of earlier recordings, and instrumental tracks.\n",
    "\n",
    "In an attempt to more easily fix lyrical errors, I wrote a function that would isolate a desired song dictionary and obtain lyrics based on the details within that dictionary. While this function worked, it relied on the compatibility of dictionary values with the Genius search. However, this incompatibility was often the cause for error and I often needed to look up individual tracks to uncover the nature of this disconnect.\n",
    "\n",
    "Overall, the corpus contains 63 winning songs and 258 non-winning, or nominated songs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Wordiness\" -- Text-type ratios and part of speech tagging\n",
    "\n",
    "##### Are winning songs utilizing a larger vocabulary?\n",
    "\n",
    "In the same loop used for tokenizing lyrics and creating word/bigram frequency lists, I added an additional step to calculate each song's text-type ratio and store it in a list for each corpus, `win_ttr` and `nom_ttr`. Before averaging the values in each list, I removed the text-token ratios associated with instrumental songs. Within the song dictionaries, the value matched to `['lyrics']` was either `'none'` or `'Instrumental'` for these tracks, resulting in a type-token ratio of `100.0`, where it should be undefined (dividing by zero). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average type-token ratio among winning songs is 40.784626607625476.\n",
      "The average type-token ratio among nominated songs is 39.211339585603504.\n"
     ]
    }
   ],
   "source": [
    "print('The average type-token ratio among winning songs is {}.'.format(sum(win_ttr) / len(win_ttr)))\n",
    "print('The average type-token ratio among nominated songs is {}.'.format(sum(nom_ttr) / len(nom_ttr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proximity of these values suggests that on average, songs that won SOTY are not necessarily using more words in their lyrics. The next step I took was to see if different *kinds* of words were being utilized, using part of speech tagging for each corpus. I chose to focus on verbs and adjectives because they might give insights to more action-oriented songs and songs containing more flowery, descriptive language. All percentages below are calculated from nested list structures `win_tagged` and `nom_tagged`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.969660916121356 percent of the tokens in all winning songs were verbs\n",
      "8.869720404521118 percent of the tokens in all winning songs were adjectives\n"
     ]
    }
   ],
   "source": [
    "print('{} percent of the tokens in all winning songs were verbs'.format(win_verb_perc))\n",
    "print('{} percent of the tokens in all winning songs were adjectives'.format(win_adj_perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.864803606565545 percent of the tokens in all nominated songs were verbs\n",
      "8.575556053699968 percent of the tokens in all nominated songs were adjectives\n"
     ]
    }
   ],
   "source": [
    "print('{} percent of the tokens in all nominated songs were verbs'.format(nom_verb_perc))\n",
    "print('{} percent of the tokens in all nominated songs were adjectives'.format(nom_adj_perc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These similar proportions of verbs and adjectives across the two sets of text suggest that neither set of songs seems to express any more \"doing\" or \"describing\" in their lyrics than the other. In fact, the two sets of songs seem to employ many of the same verbs and adjectives, displayed in the matched verb and adjective frequency tables below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be        153       be             703       \n",
      "i         136       i              591       \n",
      "are       109       is             557       \n",
      "know      90        know           516       \n",
      "make      88        do             372       \n",
      "is        76        got            302       \n",
      "go        67        was            277       \n",
      "got       65        say            259       \n",
      "dont      64        go             258       \n",
      "do        55        see            258       \n",
      "were      51        love           242       \n",
      "have      49        are            235       \n",
      "see       48        dont           227       \n",
      "love      47        want           218       \n",
      "get       44        let            201       \n",
      "say       38        have           200       \n",
      "im        38        make           200       \n",
      "want      36        get            199       \n",
      "take      33        tell           199       \n",
      "tell      33        were           195       \n",
      "had       33        been           195       \n",
      "was       32        take           195       \n",
      "come      30        feel           168       \n",
      "need      29        come           150       \n",
      "let       29        im             139       \n",
      "put       27        think          133       \n",
      "like      27        need           121       \n",
      "think     26        cant           115       \n",
      "keep      24        had            106       \n",
      "been      23        give           104       \n"
     ]
    }
   ],
   "source": [
    "### displaying 30 most frequent VERBS in winning and nominated songs, respectively\n",
    "for idx,pair in enumerate(top_win_verb):\n",
    "    print('{:<10}{:<10}{:<15}{:<10}'.format(pair[0], pair[1], top_nom_verb[idx][0], top_nom_verb[idx][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i         142       i              819       \n",
      "oh        65        oh             201       \n",
      "good      37        im             147       \n",
      "ive       34        ive            130       \n",
      "black     33        little         104       \n",
      "happy     31        good           99        \n",
      "im        28        verse          92        \n",
      "ill       24        new            87        \n",
      "whole     23        bad            71        \n",
      "beautiful 22        more           70        \n",
      "own       21        old            69        \n",
      "new       20        better         68        \n",
      "better    20        ill            66        \n",
      "single    20        dont           63        \n",
      "young     18        hard           63        \n",
      "bad       18        free           60        \n",
      "little    17        best           60        \n",
      "verse     17        true           59        \n",
      "same      16        long           58        \n",
      "true      16        big            57        \n",
      "more      15        cant           53        \n",
      "dont      15        alive          52        \n",
      "gonna     13        same           51        \n",
      "cant      12        wrong          45        \n",
      "sure      12        high           44        \n",
      "chorus    11        mum            44        \n",
      "lets      11        own            43        \n",
      "other     10        much           42        \n",
      "gray      10        yeah           42        \n",
      "mad       10        gonna          41        \n"
     ]
    }
   ],
   "source": [
    "### displaying 30 most common ADJECTIVES in winning and nominated songs, respectively\n",
    "\n",
    "for idx,pair in enumerate(top_win_adj):\n",
    "    print('{:<10}{:<10}{:<15}{:<10}'.format(pair[0], pair[1], top_nom_adj[idx][0], top_nom_adj[idx][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for deeper entry points\n",
    "##### Key terms\n",
    "First looks into the data uncovered several symmetrical qualities of the data. The next step was to zoom in, utilizing keyness analysis to better choose words for closer examination. The below table displays key terms for words in the winning set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD                     Corpus Freq.RC Freq.  Keyness\n",
      "======================================================\n",
      "worry                    33        10        72.914\n",
      "black                    33        16        59.931\n",
      "every                    78        112       58.899\n",
      "watching                 23        9         46.074\n",
      "happy                    31        23        43.812\n",
      "are                      109       235       42.034\n",
      "world                    63        107       37.511\n",
      "hmm                      17        6         35.509\n",
      "rolling                  17        7         33.317\n",
      "songs                    27        24        33.307\n",
      "whole                    23        19        30.057\n",
      "carry                    17        9         29.511\n",
      "single                   20        14        29.407\n",
      "let's                    26        26        28.997\n",
      "make                     88        208       27.485\n",
      "making                   13        5         26.231\n",
      "write                    23        23        25.651\n",
      "man                      48        88        25.228\n",
      "rose                     14        7         25.035\n",
      "we                       161       480       24.659\n"
     ]
    }
   ],
   "source": [
    "calculate_keyness(win_word_freq, nom_word_freq, top = 20) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the keyness tables, some of the most key terms in the corpus aren't distributed very widely across all the songs. Take the first word `worry` for example. It is associated with the 1989 winner, \"Don't WORRY Be Happy\" by Bobby McFerrin. Something similar happens for other key words like `rolling` (2012 winner \"Rolling in the Deep\" by Adele) and `single` (2010 winner \"Single Ladies (Put a Ring on it) by Beyonce). I suspect these words appear as key because they are repeated throughout the song, implied by presence in the title, not because they are signaling a particular kind of songwriting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalized frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first created a normalized frequency chart for the 50 most common words among the winning songs. It appeared that something similar to what happened with the keyness chart was happening again. The abbreviated display below isolates these points of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we             161     9.58\t\t480       5.98\t 24.66\n",
      "are            109     6.48\t\t235       2.93\t 42.03\n",
      "world          63      3.75\t\t107       1.33\t 37.51\n",
      "make           88      5.23\t\t208       2.59\t 27.48\n",
      "every          78      4.64\t\t112       1.39\t 58.90\n"
     ]
    }
   ],
   "source": [
    "for word, freq in win_sel: \n",
    "    win = freq\n",
    "    nom = nom_word_freq.get(word,0)\n",
    "    norm_win = win/win_size * 1000\n",
    "    norm_nom = nom/nom_size * 1000\n",
    "\n",
    "    LL = 0 if nom==0 else log_likelihood(win, win_size, nom, nom_size)\n",
    "    print(row_template.format(word, win, norm_win, nom, norm_nom, LL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words with LL values that suggest occurrence in one corpus over another are associated with the title of a song and likely appear in the chorus as well. These words are not being used in a particularly meaningful way, but are being used so often that they have this effect. This is especially plausible, considering that the corpus of winning songs is so small, with only 63 entries. Let's look closer:\n",
    "\n",
    "`we`, `are`, `world`, and `make` come from the 1986 winner, \"We Are The World\" performed by USA for Africa. The lyrics of the chorus go: `We are the world, We are the children, We are the ones to make a brighter day...`\n",
    "\n",
    "`every` is likely coming from the 1984 winner, \"Every Breath You Take\" performed by The Police. Most of the lines in this song contain the word `every` two times.\n",
    "\n",
    "Below, I isolated the counts of these words in their associated song from the rest of the winners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"we\" occurs 40 times in the song\n",
      "this comprises 24.845 percent of occurrences across all winning songs\n",
      "\n",
      "\"are\" occurs 35 times in the song\n",
      "this comprises 32.11 percent of occurrences across all winning songs\n",
      "\n",
      "\"world\" occurs 12 times in the song\n",
      "this comprises 19.048 percent of occurrences across all winning songs\n",
      "\n",
      "\"make\" occurs 23 times in the song\n",
      "this comprises 26.136 percent of occurrences across all winning songs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "usa_africa_display = ['we', 'are', 'world', 'make']\n",
    "for word in usa_africa_display:\n",
    "    print('\"{}\" occurs {} times in the song'.format(word,usa_africa.get(word)))\n",
    "    percentage = (usa_africa.get(word)/win_word_freq.get(word))*100\n",
    "    print('this comprises {:.5} percent of occurrences across all winning songs\\n'.format(percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"every\" occurs 52 times in the song\n",
      "this comprises 66.667 percent of occurrences across all winning songs\n"
     ]
    }
   ],
   "source": [
    "print('\"{}\" occurs {} times in the song'.format('every', breath.get('every')))\n",
    "percentage = (breath.get('every') / win_word_freq.get('every'))*100\n",
    "print('this comprises {:.5} percent of occurrences across all winning songs'.format(percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because these percentages suggest that some \"words of interest\" are distributed unevenly across the corpus of winning songs, I question whether this impact accurately reflects how winning songs differ from nominees. \n",
    "\n",
    "I isolated another set of terms that I thought might be interesting to investigate, related to love and time, themes from which writers might draw inspiration. Because they are common themes, the similar normalized frequencies come as no surprise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love           111     6.60\t\t657       8.18\t-4.59\n",
      "heart          59      3.51\t\t193       2.40\t 6.04\n",
      "always         26      1.55\t\t110       1.37\t 0.30\n",
      "never          66      3.93\t\t229       2.85\t 4.93\n",
      "forever        10      0.59\t\t53        0.66\t-0.09\n"
     ]
    }
   ],
   "source": [
    "for word, freq in win_entries: #top acad is a counter, make word list a counter\n",
    "    win = freq\n",
    "    nom = nom_word_freq.get(word,0)\n",
    "    norm_win = win/win_size * 1000\n",
    "    norm_nom = nom/nom_size * 1000\n",
    "\n",
    "    LL = 0 if nom==0 else log_likelihood(win, win_size, nom, nom_size)\n",
    "    print(row_template.format(word, win, norm_win, nom, norm_nom, LL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key words in context, sentiment scores\n",
    "Because the results of the normalized frequency suggested that these words occurred at similar rates in the two sets of text, I searched through concordances for the above `love` and `time` words to again see if they are employed differently. The patterns described above still held true. Take something like Tina Turner's famous song and 1985 winner, \"What's Love Got To Do With It\" for example. Among the collocates three words before or after `love`, the words in the title (and chorus) of that song have a clear presence, alongside other words that make up different iterations of \"I love you\" expressed in lyrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 31),\n",
       " ('you', 29),\n",
       " ('with', 20),\n",
       " ('love', 16),\n",
       " ('of', 15),\n",
       " (\"What's\", 15),\n",
       " ('in', 14),\n",
       " ('to', 14),\n",
       " ('that', 11),\n",
       " ('and', 10),\n",
       " ('the', 10),\n",
       " ('got', 10),\n",
       " ('do,', 10),\n",
       " ('we', 10),\n",
       " ('[Chorus]', 9),\n",
       " ('And', 8),\n",
       " ('second-hand', 8),\n",
       " ('way', 7),\n",
       " ('out', 7),\n",
       " ('your', 6)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win_love_colls.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I considered sentiment scores as another way to get at this question of how topics were being discussed in the songs. Again, the two sets of songs returned similar averages. However, I am wary of relying on sentiment scores to make any conclusions about the songs because the presence of words does not reflect how they're used or how they relate to the \"message\" or valence of the song as a whole. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average compound sentiment score for winning songs was 0.5192\n",
      "The average compound sentiment score for nominated songs was 0.4601\n"
     ]
    }
   ],
   "source": [
    "print('The average compound sentiment score for winning songs was {:.4}'.format(win_sent_score))\n",
    "print('The average compound sentiment score for nominated songs was {:.4}'.format(nom_sent_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DISCUSSION\n",
    "This analysis is inherently limited in that it only captures patterns related to lyrical content. And what it *can* capture lyrical content does not encompass the particularities of language use, such as irony. The similarities between these sets of songs does not indicate a “failed” analysis. Rather, it might suggest that final award status may be influenced by other factors, such as the cultural context or commercial success at the time of release, which were both outside the scope of this investigation. And as someone with an affinity for often wordless ambient and electronic music, disregarding song lyrics in evaluations of quality is not a hard sell! \n",
    "\n",
    "The specificity of the research question required award status as the primary dimension of analysis. However, this emphasis on the winning category fails to acknowledge that any song included in the final group of nominees (independent of award status) was already selected over numerous other entries. The intermediate tiers of selection from the date of release leading up to the award ceremony may reduce variety as similar qualities in releases are evaluated by Recording Academy members.\n",
    "\n",
    "Adjusting the research question to expand the corpus of texts might yield more meaningful differences. A combined in-group of SOTY winners and nominees could be compared to the songs at the top of the Billboard charts for corresponding years to see if there is a threshold for recognition, to assess the level of overlap, etc. \n",
    "\n",
    "Additional expansions for future research might look into the overlap between SOTY and ROTY categories in an attempt to see if songs are a “complete package” or if they can be distilled into their constituent parts (writing, production, engineering, and so on). Conducting another SOTY analysis, one could examine the idea of singular “artistic genius” through the winners of the awards, as opposed to the performing artist. This might spotlight more prolific songwriters who receive recognition for songs written by them but recorded by numerous artists. It might also highlight the degree to which Grammy-recognized artists play a role in crafting their songs. I considered this for my analysis, but failed to address naming practices expressed in credits. Credits often name individuals with their “actual” name, which does not easily align with artists who perform in a group or under a different name. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
