{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting and Organizing Data\n",
    "\n",
    "This notebook shows how I collected drama reviews for the Chinese drama *A Love So Beautiful* from MyDramaList.com.\n",
    "\n",
    "I organized these reviews in two ways, by date and by rating score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting the Corpus\n",
    "\n",
    "For my project, I need English reviews for the Chinese drama *A Love So Beautiful* and I collected 100 reviews (posted from December 2017 to December 2019) from MyDramaList.com.\n",
    "\n",
    "\n",
    "**First, I downloaded the HTML for each page of reviews.**\n",
    "\n",
    "\n",
    "To do this, \n",
    "1. Use `requests` to get HTML\n",
    "2. Write the text of response objects to the `data/raw_HTML` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/raw_HTML'):\n",
    "    os.makedirs('data/raw_HTML')\n",
    "\n",
    "## make a \"raw_HTML\" folder in the \"data\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = {'User_Agent':'Mozilla/5.0'}\n",
    "\n",
    "page_url = 'https://mydramalist.com/24644-a-love-so-beautiful/reviews?sort=recent&xlang=en-US&page={}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving https://mydramalist.com/24644-a-love-so-beautiful/reviews?sort=recent&xlang=en-US&page=1\n",
      "Retrieving https://mydramalist.com/24644-a-love-so-beautiful/reviews?sort=recent&xlang=en-US&page=2\n",
      "Retrieving https://mydramalist.com/24644-a-love-so-beautiful/reviews?sort=recent&xlang=en-US&page=3\n",
      "Retrieving https://mydramalist.com/24644-a-love-so-beautiful/reviews?sort=recent&xlang=en-US&page=4\n",
      "Retrieving https://mydramalist.com/24644-a-love-so-beautiful/reviews?sort=recent&xlang=en-US&page=5\n",
      "Retrieving https://mydramalist.com/24644-a-love-so-beautiful/reviews?sort=recent&xlang=en-US&page=6\n",
      "Retrieving https://mydramalist.com/24644-a-love-so-beautiful/reviews?sort=recent&xlang=en-US&page=7\n",
      "Retrieving https://mydramalist.com/24644-a-love-so-beautiful/reviews?sort=recent&xlang=en-US&page=8\n",
      "Retrieving https://mydramalist.com/24644-a-love-so-beautiful/reviews?sort=recent&xlang=en-US&page=9\n"
     ]
    }
   ],
   "source": [
    "for page in range(1, 10):    ## We need 9 pages and the range is end exclusive, so the range should go from 1 to 10\n",
    "    current_url = page_url.format(page)\n",
    "    print('Retrieving', current_url)    ## to show the link for the page that is being retrieved\n",
    "\n",
    "    resp = requests.get(current_url, headers = user_agent)\n",
    "    \n",
    "    while not resp.ok:\n",
    "        print('error...retrying')\n",
    "        time.sleep(2.0)     ## delay execution for 2 seconds\n",
    "        resp = requests.get(current_url, headers = user_agent)\n",
    "    \n",
    "    html = resp.text\n",
    "    \n",
    "    with open('data/raw_HTML/page{}.html'.format(page), 'w') as out:\n",
    "        out.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['page1.html',\n",
       " 'page2.html',\n",
       " 'page3.html',\n",
       " 'page4.html',\n",
       " 'page5.html',\n",
       " 'page6.html',\n",
       " 'page7.html',\n",
       " 'page8.html',\n",
       " 'page9.html']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data/raw_HTML')   ## show a list of file names in the directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then, I extracted the reviews from each downloaded HTML page.**\n",
    "\n",
    "Four steps need to be done:\n",
    "1. Load the HTML into a `string` object;\n",
    "2. Parse the `string` object into `BeautifulSoup`;\n",
    "3. Find all `<div>` elements that contain reviews;\n",
    "4. Extract the *review text*, *username*, *overall score*, and *date* on which the review was posted.\n",
    "\n",
    "Two functions were built to carry out these steps.\n",
    "* `process_html` function - To load the HTML from the files saved earlier and to get a list of `<div class=\"review\">` BeautifulSoup objects\n",
    "* `process_review` function - To take a BeautifulSoup object for the `<div class=\"review\">` and to return a dictionary that contains the *review text*, *username*, *overall score*, and *date*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_html(filename):\n",
    "    \n",
    "    ## 1. load HTML\n",
    "    fpath = os.path.join('data', 'raw_HTML', filename)    ## join two or more pathname components\n",
    "    \n",
    "    if not os.path.exists(fpath):    ## test to see if a path exists\n",
    "        return None\n",
    "    \n",
    "    print('Processing', fpath)\n",
    "    \n",
    "    html = open(fpath).read()      ## load HTML into a string object\n",
    "    \n",
    "    \n",
    "    ## 2. create a BeautifulSoup object\n",
    "    doc = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    \n",
    "    ## 3. find all <div class=\"review\"> elements\n",
    "    rev_divs = doc.find_all('div', attrs = {'class':'review'})\n",
    "    \n",
    "    num_of_rev = len(rev_divs)\n",
    "    print ('Found {} reviews'.format(num_of_rev))\n",
    "    \n",
    "    return rev_divs        ## return a list of <div class=\"review\"> BeautifulSoup objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_review(rev):\n",
    "    \n",
    "    username = rev.find('b').text\n",
    "    overall_score = rev.find('span', attrs = {'class':'score pull-right'}).text\n",
    "    time_posted = rev.find('small', attrs = {'class':'datetime'}).text\n",
    "    \n",
    "    review_dict = {}\n",
    "    review_dict['Username'] = username\n",
    "    review_dict['Overall Score'] = overall_score\n",
    "    review_dict['Date'] = time_posted\n",
    "    \n",
    "    rev_body = rev.find('div', attrs = {'class':re.compile('review-body(full-read)?')})\n",
    "        ## re.compile() compiles a regular expression pattern\n",
    "        ## the \"?\" indicates zero or one occurrences of the preceding element \"full-read\"\n",
    "    \n",
    "    rev_text_list = rev_body.findChildren(text = True, recursive = False)\n",
    "        ## recursive tells BeautifulSoup whether to go all the way down the parse tree\n",
    "        ## recursive = False means only the immediate children of the tag are searched\n",
    "    rev_text = '\\n\\n'.join(rev_text_list).strip()\n",
    "    \n",
    "    review_dict['Review Text'] = rev_text\n",
    "    \n",
    "    return review_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_files = []\n",
    "\n",
    "for file in os.listdir('data/raw_HTML'):\n",
    "    if file.endswith('.html'):\n",
    "        html_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data/raw_HTML/page1.html\n",
      "Found 12 reviews\n",
      "Processing data/raw_HTML/page2.html\n",
      "Found 12 reviews\n",
      "Processing data/raw_HTML/page3.html\n",
      "Found 12 reviews\n",
      "Processing data/raw_HTML/page4.html\n",
      "Found 12 reviews\n",
      "Processing data/raw_HTML/page5.html\n",
      "Found 12 reviews\n",
      "Processing data/raw_HTML/page6.html\n",
      "Found 12 reviews\n",
      "Processing data/raw_HTML/page7.html\n",
      "Found 12 reviews\n",
      "Processing data/raw_HTML/page8.html\n",
      "Found 12 reviews\n",
      "Processing data/raw_HTML/page9.html\n",
      "Found 11 reviews\n"
     ]
    }
   ],
   "source": [
    "review_data = []\n",
    "\n",
    "for page_html in html_files:\n",
    "    rev_divs = process_html(page_html)\n",
    "## process the HTML and get <div class=\"review\"> BeautifulSoup objects\n",
    "\n",
    "    for rev in rev_divs:\n",
    "        rev_info = process_review(rev)\n",
    "        review_data.append(rev_info)\n",
    "    ## extract username, overall score, review text, and date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a list of reviews.\n",
    "\n",
    "Each review is a dictionary that has four keys: 1) Username, 2) Overall Score, 3) Review Text, and 4) Date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of 107 English reviews for *A Love So Beautiful* on MyDramaList.com, but 7 of them were posted in 2020, which is out of the time range I am interested in (i.e., December 2017 to December 2019). I will disregard these 7 reviews in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is one of the reviews.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Date': 'Jun  2, 2019',\n",
       " 'Overall Score': '9.5',\n",
       " 'Review Text': \"To be honest, I went into this thinking I was going to hate it. The fact that the FL already had a huge crush on the ML and was super obvious and desperate about it was something I just knew I was going to cringe at—and that's the only reason why I couldn't give this one a full 10/10.\\n\\nObviously, I ended up enjoying this a LOT more than I expected. It was super cute and I loved all the little things that the ML did for the FL without her knowing. I know the second lead did a lot of stuff too—and that a lot of people had second lead syndrome but I actually did not, whew!\\n\\nI was also hesitant about this drama because of the time jumps that I knew happened throughout the later episodes. These are so easily ruined, but the drama actually did a really good job of dealing with the relationship growths during the time we didn't see.\\n\\nOverall, this was a really great story about romance and friendship, and I am so happy both the ships in this sailed :')\",\n",
       " 'Username': 'Catherine Hsu'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Here is one of the reviews.')\n",
    "\n",
    "review_data[21]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next, I saved the list of reviews as a JSON file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/all_reviews_info.json', 'w') as out:\n",
    "    out.write(json.dumps(review_data, indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing the Reviews\n",
    "\n",
    "**All reviews from 2017 to 2019**\n",
    "* I created a file in the `data` folder to hold all the reviews posted from 2017 to 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_2017_to_2019 = []\n",
    "\n",
    "for review in review_data:\n",
    "    if '2017' in review['Date']:\n",
    "        review_2017_to_2019.append(review)\n",
    "    if '2018' in review['Date']:\n",
    "        review_2017_to_2019.append(review)  \n",
    "    if '2019' in review['Date']:\n",
    "        review_2017_to_2019.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_2017_to_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/review_2017_to_2019.json', 'w') as out:\n",
    "    out.write(json.dumps(review_2017_to_2019, indent = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Organize by Year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_2017 = []\n",
    "\n",
    "for review in review_2017_to_2019:\n",
    "    if '2017' in review['Date']:\n",
    "        review_2017.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/Date/review_2017.json', 'w') as out:\n",
    "    out.write(json.dumps(review_2017, indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_2018 = []\n",
    "\n",
    "for review in review_2017_to_2019:\n",
    "    if '2018' in review['Date']:\n",
    "        review_2018.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/Date/review_2018.json', 'w') as out:\n",
    "    out.write(json.dumps(review_2018, indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_2019 = []\n",
    "\n",
    "for review in review_2017_to_2019:\n",
    "    if '2019' in review['Date']:\n",
    "        review_2019.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/Date/review_2019.json', 'w') as out:\n",
    "    out.write(json.dumps(review_2019, indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100 reviews in total from 2017 to 2019.\n"
     ]
    }
   ],
   "source": [
    "print('There are {} reviews in total from 2017 to 2019.'.format(len(review_2017) + len(review_2018) + len(review_2019)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Organize by Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_0_to_3 = []\n",
    "\n",
    "for review in review_2017:\n",
    "    if float(review['Overall Score']) <= 3:       ## float() converts a string to a floating point number\n",
    "        score_0_to_3.append(review)\n",
    "        \n",
    "for review in review_2018:\n",
    "    if float(review['Overall Score']) <= 3:\n",
    "        score_0_to_3.append(review)\n",
    "\n",
    "for review in review_2019:\n",
    "    if float(review['Overall Score']) <= 3:\n",
    "        score_0_to_3.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(score_0_to_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/Overall_Score/score_0_to_3.json', 'w') as out:\n",
    "    out.write(json.dumps(score_0_to_3, indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_3_to_6 = []\n",
    "\n",
    "for review in review_2017:\n",
    "    if float(review['Overall Score']) > 3 and float(review['Overall Score']) <= 6:\n",
    "        score_3_to_6.append(review)\n",
    "        \n",
    "for review in review_2018:\n",
    "    if float(review['Overall Score']) > 3 and float(review['Overall Score']) <= 6:\n",
    "        score_3_to_6.append(review)\n",
    "\n",
    "for review in review_2019:\n",
    "    if float(review['Overall Score']) > 3 and float(review['Overall Score']) <= 6:\n",
    "        score_3_to_6.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(score_3_to_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/Overall_Score/score_3_to_6.json', 'w') as out:\n",
    "    out.write(json.dumps(score_3_to_6, indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_6_to_8 = []\n",
    "\n",
    "for review in review_2017:\n",
    "    if float(review['Overall Score']) > 6 and float(review['Overall Score']) <= 8:\n",
    "        score_6_to_8.append(review)\n",
    "        \n",
    "for review in review_2018:\n",
    "    if float(review['Overall Score']) > 6 and float(review['Overall Score']) <= 8:\n",
    "        score_6_to_8.append(review)\n",
    "        \n",
    "for review in review_2019:\n",
    "    if float(review['Overall Score']) > 6 and float(review['Overall Score']) <= 8:\n",
    "        score_6_to_8.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(score_6_to_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/Overall_Score/score_6_to_8.json', 'w') as out:\n",
    "    out.write(json.dumps(score_6_to_8, indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_8_to_10 = []\n",
    "\n",
    "for review in review_2017:\n",
    "    if float(review['Overall Score']) > 8 and float(review['Overall Score']) <= 10:\n",
    "        score_8_to_10.append(review)\n",
    "\n",
    "for review in review_2018:\n",
    "    if float(review['Overall Score']) > 8 and float(review['Overall Score']) <= 10:\n",
    "        score_8_to_10.append(review)\n",
    "        \n",
    "for review in review_2019:\n",
    "    if float(review['Overall Score']) > 8 and float(review['Overall Score']) <= 10:\n",
    "        score_8_to_10.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(score_8_to_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/Overall_Score/score_8_to_10.json', 'w') as out:\n",
    "    out.write(json.dumps(score_8_to_10, indent = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a list of files in the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " '.ipynb_checkpoints',\n",
       " 'Overall_Score',\n",
       " 'raw_HTML',\n",
       " 'all_reviews_info.json',\n",
       " 'review_2017_to_2019.json']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a list of files in the `data/Date` folder and in the `data/Overall_Score` folder, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['review_2017.json', 'review_2018.json', 'review_2019.json']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data/Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['score_0_to_3.json',\n",
       " 'score_3_to_6.json',\n",
       " 'score_6_to_8.json',\n",
       " 'score_8_to_10.json']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data/Overall_Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I organized my data in two ways:\n",
    "1. by date (on which the review was posted)\n",
    "2. by overall score\n",
    "\n",
    "These are also the two key dimensions of my analysis.\n",
    "\n",
    "For the \"date\" dimension, I separated the review data by year.\n",
    "* Reviews from 2017\n",
    "* Reviews from 2018\n",
    "* Reviews from 2019\n",
    "\n",
    "Reviews from the same year are in the same JSON file with filename `review_{year}`. These three files are in a folder named `Date`.\n",
    "\n",
    "For the \"overall score\" dimension, I separated the review data by the overall score.\n",
    "* Reviews with a score between 0 to 3.0 -- these scores mean the drama is \"poor\"\n",
    "* Reviews with a score between 3.0 to 6.0 -- these scores mean the drama is \"so-so\"\n",
    "* Reviews with a score between 6.0 to 8.0 -- these scores mean the drama is \"good\"\n",
    "* Reviews with a score between 8.0 to 10 -- these scores mean the drama is \"excellent\"\n",
    "\n",
    "Reviews with a score in the indicated score range are in the same JSON file with filename `score_{}_to_{}`. These four files are in a folder named `Overall_Score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder name              \tnumber of texts\n",
      "==================================================\n",
      "Date                          \t3   texts\n",
      ".ipynb_checkpoints            \t0   texts\n",
      "Overall_Score                 \t4   texts\n",
      "raw_HTML                      \t9   texts\n"
     ]
    }
   ],
   "source": [
    "print('{: <25}\\t{}'.format('folder name', 'number of texts'))\n",
    "print('=====' * 10)\n",
    "\n",
    "for file in os.listdir('data'):\n",
    "    doc = os.path.join('data', file)\n",
    "    try:\n",
    "        num_of_docs = len(os.listdir(doc))\n",
    "    except NotADirectoryError:         ## skip the all_reviews_info.json and review_2017_to_2019.json\n",
    "        continue;\n",
    "    print('{: <30}\\t{: <3} texts'.format(file, num_of_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `Date` folder, each text is a list of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['review_2017.json', 'review_2018.json', 'review_2019.json']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data/Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18 dictionaries in review_2017.json.\n",
      "There are 58 dictionaries in review_2018.json.\n",
      "There are 24 dictionaries in review_2019.json.\n"
     ]
    }
   ],
   "source": [
    "for year in os.listdir('data/Date'):\n",
    "    rev_by_year = open('data/Date/{}'.format(year))\n",
    "    num_of_reviews_by_year = len(json.load(rev_by_year))\n",
    "    print('There are {} dictionaries in {}.'.format(num_of_reviews_by_year, year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, in the `Overall_Score` folder, each text is also a list of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 dictionaries in score_0_to_3.json.\n",
      "There are 7 dictionaries in score_3_to_6.json.\n",
      "There are 13 dictionaries in score_6_to_8.json.\n",
      "There are 80 dictionaries in score_8_to_10.json.\n"
     ]
    }
   ],
   "source": [
    "for score in os.listdir('data/Overall_Score'):\n",
    "    rev_by_score = open('data/Overall_Score/{}'.format(score))\n",
    "    num_of_reviews_by_score = len(json.load(rev_by_score))\n",
    "    print('There are {} dictionaries in {}.'.format(num_of_reviews_by_score, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
